{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = sagemaker.Session().boto_region_name\n",
    "\n",
    "boto3.setup_default_session(region_name = region)\n",
    "boto_session = boto3.Session(region_name = region)\n",
    "\n",
    "s3_client = boto3.client(\"s3\", region_name = region)\n",
    "\n",
    "sagemaker_boto_client = boto_session.client(\"sagemaker\")\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session = boto_session, sagemaker_client = sagemaker_boto_client\n",
    ")\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "sagemaker_role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"ideaaiml-demo\"\n",
    "prefix = \"mlops/predictive-maintenance\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Test Data with headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"datasets/train-test/test.csv\")\n",
    "test_data = test_data.drop(\"failure\", axis = 1)\n",
    "test_data.to_csv(\"datasets/train-test/test_data_with_headers.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Monitor Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "test_data_drift_monitor = DefaultModelMonitor(\n",
    "    role = sagemaker_role,\n",
    "    instance_count = 1,\n",
    "    instance_type = \"ml.m5.xlarge\",\n",
    "    volume_size_in_gb = 1,\n",
    "    max_runtime_in_seconds = 360,\n",
    "    sagemaker_session = sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggest Baselining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name PdM-Baseline-Job-Data-Monitor-2023-05-10-0820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\u001b[34m2023-05-10 08:25:14,689 - matplotlib.font_manager - INFO - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:15.277498: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:15.277529: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:17.013118: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:17.013150: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:17.013174: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-134-245.ec2.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:17.013452: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:18,678 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:451633145432:processing-job/pdm-baseline-job-data-monitor-2023-05-10-0820', 'ProcessingJobName': 'PdM-Baseline-Job-Data-Monitor-2023-05-10-0820', 'Environment': {'dataset_format': '{\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '156813124566.dkr.ecr.us-east-1.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'AppManaged': False, 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://sagemaker-us-east-1-451633145432/model-monitor/baselining/PdM-Baseline-Job-Data-Monitor-2023-05-10-0820/input/baseline_dataset_input', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}, 'DatasetDefinition': None}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'AppManaged': False, 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://ideaaiml-demo/mlops/predictive-maintenance/data/baselining/test-header-data-results', 'S3UploadMode': 'EndOfJob'}, 'FeatureStoreOutput': None}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 1, 'VolumeKmsKeyId': None}}, 'RoleArn': 'arn:aws:iam::451633145432:role/service-role/AmazonSageMaker-ExecutionRole-20220302T144665', 'StoppingCondition': {'MaxRuntimeInSeconds': 360}}\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:18,678 - __main__ - INFO - Current Environment:{'dataset_format': '{\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:18,678 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"csv\": {\"header\": true, \"output_columns_position\": \"START\"}}, \"output_path\": \"/opt/ml/processing/output\", \"monitoring_input_type\": null, \"analysis_type\": null, \"problem_type\": null, \"inference_attribute\": null, \"probability_attribute\": null, \"ground_truth_attribute\": null, \"probability_threshold_attribute\": null, \"positive_label\": null, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"start_time\": null, \"end_time\": null, \"metric_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\", \"detect_outliers\": null, \"detect_drift\": null, \"image_data\": null, \"report_enabled\": false, \"auto_ml_job_detail\": null}\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:18,678 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:18,678 - bootstrap - INFO - Copy aws jars\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:18,735 - bootstrap - INFO - Copy cluster config\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:18,735 - bootstrap - INFO - Write runtime cluster config\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:18,736 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'hosts': ['algo-1']}\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:18,753 - bootstrap - INFO - Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:18,753 - bootstrap - INFO - Starting spark process for master node algo-1\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:18,753 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,254 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.134.245\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.0.0\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3\u001b[0m\n",
      "\u001b[34m.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_362\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,262 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,265 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-eaefaa62-0b59-4c0b-af0d-48ad106ee6bc\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,787 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,799 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,800 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,802 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,807 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,807 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,807 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,807 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,841 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,852 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,852 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,856 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,859 INFO blockmanagement.BlockManager: The block deletion will start around 2023 May 10 08:25:19\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,860 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,861 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,862 INFO util.GSet: 2.0% max memory 3.1 GB = 63.2 MB\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,862 INFO util.GSet: capacity      = 2^23 = 8388608 entries\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,939 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,942 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,943 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,943 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,943 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,943 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,943 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,943 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,943 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,943 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,943 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,943 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,970 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,970 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,971 INFO util.GSet: 1.0% max memory 3.1 GB = 31.6 MB\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,971 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,973 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,973 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,973 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,973 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,979 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,982 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,982 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,983 INFO util.GSet: 0.25% max memory 3.1 GB = 7.9 MB\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,983 INFO util.GSet: capacity      = 2^20 = 1048576 entries\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,989 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,989 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,989 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,993 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,993 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,994 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,994 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,995 INFO util.GSet: 0.029999999329447746% max memory 3.1 GB = 970.6 KB\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:19,995 INFO util.GSet: capacity      = 2^17 = 131072 entries\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:20,016 INFO namenode.FSImage: Allocated new BlockPoolId: BP-979993644-10.0.134.245-1683707120010\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:20,029 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:20,037 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:20,116 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:20,129 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:20,133 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.0.134.245\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:20,144 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:22,210 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:22,211 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:24,290 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:24,290 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:26,375 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:26,375 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:28,483 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:28,483 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:30,877 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:30,877 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:40,883 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:42,539 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:42,956 INFO Main: Start analyzing with args: --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:42,992 INFO Main: Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json,yarn)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,003 INFO FileUtil: Read file from path /tmp/spark_job_config.json.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,421 INFO spark.SparkContext: Running Spark version 3.3.0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,444 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,444 INFO resource.ResourceUtils: No custom resources configured for spark.driver.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,445 INFO resource.ResourceUtils: ==============================================================\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,446 INFO spark.SparkContext: Submitted application: SageMakerDataAnalyzer\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,475 INFO resource.ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 3, script: , vendor: , memory -> name: memory, amount: 11412, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,492 INFO resource.ResourceProfile: Limiting resource is cpus at 3 tasks per executor\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,494 INFO resource.ResourceProfileManager: Added ResourceProfile id: 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,543 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,543 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,543 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,544 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,544 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,896 INFO util.Utils: Successfully started service 'sparkDriver' on port 39315.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,925 INFO spark.SparkEnv: Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,958 INFO spark.SparkEnv: Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,981 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:43,982 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:44,014 INFO spark.SparkEnv: Registering BlockManagerMasterHeartbeat\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:44,036 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-1a46a657-6720-47b4-b7ab-f68ee0f49190\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:44,054 INFO memory.MemoryStore: MemoryStore started with capacity 1458.6 MiB\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:44,090 INFO spark.SparkEnv: Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:44,127 INFO spark.SparkContext: Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.0.134.245:39315/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1683707143417\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:44,589 INFO client.RMProxy: Connecting to ResourceManager at /10.0.134.245:8032\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:45,455 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:45,455 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:45,465 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (15563 MB per container)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:45,465 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:45,465 INFO yarn.Client: Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:45,466 INFO yarn.Client: Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:45,471 INFO yarn.Client: Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:45,554 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:47,332 INFO yarn.Client: Uploading resource file:/tmp/spark-36275649-b250-4c5c-b479-b6bc362172c1/__spark_libs__6387724103745067267.zip -> hdfs://10.0.134.245/user/root/.sparkStaging/application_1683707126105_0001/__spark_libs__6387724103745067267.zip\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:50,303 INFO yarn.Client: Uploading resource file:/tmp/spark-36275649-b250-4c5c-b479-b6bc362172c1/__spark_conf__1809585395305894456.zip -> hdfs://10.0.134.245/user/root/.sparkStaging/application_1683707126105_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:50,353 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:50,354 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:50,354 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:50,354 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:50,354 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:50,392 INFO yarn.Client: Submitting application application_1683707126105_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:50,778 INFO impl.YarnClientImpl: Submitted application application_1683707126105_0001\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:51,783 INFO yarn.Client: Application report for application_1683707126105_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:51,788 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: AM container is launched, waiting for AM container to Register with RM\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1683707150495\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1683707126105_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:52,791 INFO yarn.Client: Application report for application_1683707126105_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:53,794 INFO yarn.Client: Application report for application_1683707126105_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:54,798 INFO yarn.Client: Application report for application_1683707126105_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:55,801 INFO yarn.Client: Application report for application_1683707126105_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:56,095 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1683707126105_0001), /proxy/application_1683707126105_0001\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:56,805 INFO yarn.Client: Application report for application_1683707126105_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:56,806 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.0.134.245\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1683707150495\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1683707126105_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:56,808 INFO cluster.YarnClientSchedulerBackend: Application application_1683707126105_0001 has started running.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:56,836 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44755.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:56,836 INFO netty.NettyBlockTransferService: Server created on 10.0.134.245:44755\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:56,838 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:56,859 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.134.245, 44755, None)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:56,863 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.134.245:44755 with 1458.6 MiB RAM, BlockManagerId(driver, 10.0.134.245, 44755, None)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:56,869 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.134.245, 44755, None)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:56,870 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.134.245, 44755, None)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:57,049 INFO util.log: Logging initialized @15897ms to org.sparkproject.jetty.util.log.Slf4jLog\u001b[0m\n",
      "\u001b[34m2023-05-10 08:25:57,710 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:01,349 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.134.245:59834) with ID 1,  ResourceProfileId 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:01,491 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-1:37329 with 5.8 GiB RAM, BlockManagerId(1, algo-1, 37329, None)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:14,461 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000000000(ns)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:14,659 WARN spark.SparkContext: Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:14,725 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:14,730 INFO internal.SharedState: Warehouse path is 'file:/usr/spark-3.3.0/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:15,817 INFO datasources.InMemoryFileIndex: It took 48 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:15,997 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 416.9 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,311 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 39.3 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,315 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.134.245:44755 (size: 39.3 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,320 INFO spark.SparkContext: Created broadcast 0 from csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,724 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,727 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,733 INFO input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,792 INFO spark.SparkContext: Starting job: csv at DatasetReader.scala:99\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,811 INFO scheduler.DAGScheduler: Got job 0 (csv at DatasetReader.scala:99) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,812 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at DatasetReader.scala:99)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,812 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,814 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,819 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,863 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.3 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,867 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,867 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.134.245:44755 (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,868 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,886 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at csv at DatasetReader.scala:99) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,887 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:16,932 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4635 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:17,164 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on algo-1:37329 (size: 4.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:18,050 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on algo-1:37329 (size: 39.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:18,416 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1498 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:18,418 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:18,426 INFO scheduler.DAGScheduler: ResultStage 0 (csv at DatasetReader.scala:99) finished in 1.585 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:18,430 INFO scheduler.DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:18,431 INFO cluster.YarnScheduler: Killing all running tasks in stage 0: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:18,434 INFO scheduler.DAGScheduler: Job 0 finished: csv at DatasetReader.scala:99, took 1.642105 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:18,651 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 10.0.134.245:44755 in memory (size: 39.3 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:18,652 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on algo-1:37329 in memory (size: 39.3 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:18,669 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.134.245:44755 in memory (size: 4.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:18,677 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on algo-1:37329 in memory (size: 4.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:20,839 INFO datasources.FileSourceStrategy: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:20,841 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:20,844 INFO datasources.FileSourceStrategy: Output Data Schema: struct<voltmean_3h: string, rotatemean_3h: string, pressuremean_3h: string, vibrationmean_3h: string, voltsd_3h: string ... 28 more fields>\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:20,887 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,074 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 416.5 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,089 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 39.2 KiB, free 1458.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,090 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.134.245:44755 (size: 39.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,092 INFO spark.SparkContext: Created broadcast 2 from head at DataAnalyzer.scala:100\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,108 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 9923905 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,154 INFO spark.SparkContext: Starting job: head at DataAnalyzer.scala:100\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,155 INFO scheduler.DAGScheduler: Got job 1 (head at DataAnalyzer.scala:100) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,156 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (head at DataAnalyzer.scala:100)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,156 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,159 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,161 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:100), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,246 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 21.3 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,249 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 9.1 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,249 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.134.245:44755 (size: 9.1 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,251 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,252 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at head at DataAnalyzer.scala:100) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,252 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,257 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4963 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:21,334 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-1:37329 (size: 9.1 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:22,283 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on algo-1:37329 (size: 39.2 KiB, free: 5.8 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:24,560 INFO storage.BlockManagerInfo: Added rdd_7_0 in memory on algo-1:37329 (size: 24.9 MiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:24,694 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3440 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:24,695 INFO scheduler.DAGScheduler: ResultStage 1 (head at DataAnalyzer.scala:100) finished in 3.530 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:24,696 INFO scheduler.DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:24,696 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:24,696 INFO cluster.YarnScheduler: Killing all running tasks in stage 1: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:24,697 INFO scheduler.DAGScheduler: Job 1 finished: head at DataAnalyzer.scala:100, took 3.542503 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:25,027 INFO codegen.CodeGenerator: Code generated in 244.663511 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:25,773 INFO scheduler.DAGScheduler: Registering RDD 16 (collect at AnalysisRunner.scala:326) as input to shuffle 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:25,776 INFO scheduler.DAGScheduler: Got map stage job 2 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:25,777 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:25,777 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:25,779 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:25,782 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:25,808 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 118.1 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:25,810 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.9 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:25,811 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.134.245:44755 (size: 35.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:25,812 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:25,814 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[16] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:25,814 INFO cluster.YarnScheduler: Adding task set 2.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:25,823 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:25,849 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-1:37329 (size: 35.9 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,504 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 1683 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,504 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,507 INFO scheduler.DAGScheduler: ShuffleMapStage 2 (collect at AnalysisRunner.scala:326) finished in 1.721 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,508 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,509 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,510 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,510 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,599 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,601 INFO scheduler.DAGScheduler: Got job 3 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,601 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,601 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,601 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,602 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,617 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 171.0 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,619 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 47.1 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,619 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.134.245:44755 (size: 47.1 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,620 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,621 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,621 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,623 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,639 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on algo-1:37329 (size: 47.1 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,678 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.134.245:59834\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,986 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 363 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,986 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,989 INFO scheduler.DAGScheduler: ResultStage 4 (collect at AnalysisRunner.scala:326) finished in 0.380 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,991 INFO scheduler.DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,991 INFO cluster.YarnScheduler: Killing all running tasks in stage 4: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:27,991 INFO scheduler.DAGScheduler: Job 3 finished: collect at AnalysisRunner.scala:326, took 0.391914 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:28,045 INFO codegen.CodeGenerator: Code generated in 42.658807 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:28,398 INFO codegen.CodeGenerator: Code generated in 34.470027 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:28,495 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:28,497 INFO scheduler.DAGScheduler: Got job 4 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:28,497 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:28,497 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:28,498 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:28,503 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:28,537 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 41.8 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:28,541 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:28,543 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.134.245:44755 (size: 17.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:28,547 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:28,547 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:28,547 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:28,550 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4963 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:28,568 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-1:37329 (size: 17.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:30,574 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 2025 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:30,575 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:30,576 INFO scheduler.DAGScheduler: ResultStage 5 (treeReduce at KLLRunner.scala:107) finished in 2.070 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:30,576 INFO scheduler.DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:30,576 INFO cluster.YarnScheduler: Killing all running tasks in stage 5: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:30,577 INFO scheduler.DAGScheduler: Job 4 finished: treeReduce at KLLRunner.scala:107, took 2.081099 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:30,649 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.0.134.245:44755 in memory (size: 17.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:30,651 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on algo-1:37329 in memory (size: 17.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:30,693 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.134.245:44755 in memory (size: 47.1 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:30,702 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on algo-1:37329 in memory (size: 47.1 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:30,728 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.134.245:44755 in memory (size: 35.9 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:30,737 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-1:37329 in memory (size: 35.9 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:30,751 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.134.245:44755 in memory (size: 9.1 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:30,754 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on algo-1:37329 in memory (size: 9.1 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,198 INFO codegen.CodeGenerator: Code generated in 99.766192 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,207 INFO scheduler.DAGScheduler: Registering RDD 34 (collect at AnalysisRunner.scala:326) as input to shuffle 1\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,208 INFO scheduler.DAGScheduler: Got map stage job 5 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,208 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,208 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,209 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,210 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,216 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 77.3 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,218 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,219 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.134.245:44755 (size: 24.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,219 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,220 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[34] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,221 INFO cluster.YarnScheduler: Adding task set 6.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,223 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,237 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-1:37329 (size: 24.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,848 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 625 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,849 INFO scheduler.DAGScheduler: ShuffleMapStage 6 (collect at AnalysisRunner.scala:326) finished in 0.638 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,851 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,851 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,851 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,852 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:31,851 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,040 INFO codegen.CodeGenerator: Code generated in 108.392386 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,061 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,063 INFO scheduler.DAGScheduler: Got job 6 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,063 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,063 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,063 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,064 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,071 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 66.2 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,073 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,075 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.134.245:44755 (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,075 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,076 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[37] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,076 INFO cluster.YarnScheduler: Adding task set 8.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,077 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,099 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on algo-1:37329 (size: 19.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,110 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 10.0.134.245:59834\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,194 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 117 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,194 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,196 INFO scheduler.DAGScheduler: ResultStage 8 (collect at AnalysisRunner.scala:326) finished in 0.126 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,196 INFO scheduler.DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,196 INFO cluster.YarnScheduler: Killing all running tasks in stage 8: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,196 INFO scheduler.DAGScheduler: Job 6 finished: collect at AnalysisRunner.scala:326, took 0.134673 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,264 INFO codegen.CodeGenerator: Code generated in 49.713466 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,654 INFO scheduler.DAGScheduler: Registering RDD 42 (collect at AnalysisRunner.scala:326) as input to shuffle 2\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,654 INFO scheduler.DAGScheduler: Got map stage job 7 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,655 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 9 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,655 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,655 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,656 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,663 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 87.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,665 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,666 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.134.245:44755 (size: 28.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,668 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,668 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[42] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,669 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,670 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:32,680 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on algo-1:37329 (size: 28.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,124 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 454 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,124 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,125 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (collect at AnalysisRunner.scala:326) finished in 0.467 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,125 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,125 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,125 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,125 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,163 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,165 INFO scheduler.DAGScheduler: Got job 8 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,165 INFO scheduler.DAGScheduler: Final stage: ResultStage 11 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,165 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,165 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,166 INFO scheduler.DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[45] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,175 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 172.1 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,178 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 47.3 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,179 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.134.245:44755 (size: 47.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,179 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,180 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[45] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,180 INFO cluster.YarnScheduler: Adding task set 11.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,181 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 8) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,193 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on algo-1:37329 (size: 47.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,204 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.0.134.245:59834\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,335 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 8) in 154 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,335 INFO cluster.YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,336 INFO scheduler.DAGScheduler: ResultStage 11 (collect at AnalysisRunner.scala:326) finished in 0.168 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,345 INFO scheduler.DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,345 INFO cluster.YarnScheduler: Killing all running tasks in stage 11: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,345 INFO scheduler.DAGScheduler: Job 8 finished: collect at AnalysisRunner.scala:326, took 0.182015 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,470 INFO codegen.CodeGenerator: Code generated in 16.779875 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,498 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,499 INFO scheduler.DAGScheduler: Got job 9 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,499 INFO scheduler.DAGScheduler: Final stage: ResultStage 12 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,499 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,500 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,502 INFO scheduler.DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[55] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,510 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 41.7 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,512 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,513 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.134.245:44755 (size: 17.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,513 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,514 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[55] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,514 INFO cluster.YarnScheduler: Adding task set 12.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,516 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 12.0 (TID 9) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4963 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:33,526 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on algo-1:37329 (size: 17.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,175 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 12.0 (TID 9) in 1659 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,176 INFO scheduler.DAGScheduler: ResultStage 12 (treeReduce at KLLRunner.scala:107) finished in 1.673 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,177 INFO scheduler.DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,176 INFO cluster.YarnScheduler: Removed TaskSet 12.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,178 INFO cluster.YarnScheduler: Killing all running tasks in stage 12: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,178 INFO scheduler.DAGScheduler: Job 9 finished: treeReduce at KLLRunner.scala:107, took 1.680166 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,219 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 10.0.134.245:44755 in memory (size: 47.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,226 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on algo-1:37329 in memory (size: 47.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,251 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 10.0.134.245:44755 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,256 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on algo-1:37329 in memory (size: 19.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,273 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.0.134.245:44755 in memory (size: 24.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,274 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on algo-1:37329 in memory (size: 24.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,283 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.134.245:44755 in memory (size: 28.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,285 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on algo-1:37329 in memory (size: 28.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,359 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 10.0.134.245:44755 in memory (size: 17.2 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,374 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on algo-1:37329 in memory (size: 17.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,517 INFO codegen.CodeGenerator: Code generated in 67.218769 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,528 INFO scheduler.DAGScheduler: Registering RDD 60 (collect at AnalysisRunner.scala:326) as input to shuffle 3\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,528 INFO scheduler.DAGScheduler: Got map stage job 10 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,528 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 13 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,528 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,529 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,530 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[60] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,534 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 77.3 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,537 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,537 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.134.245:44755 (size: 24.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,538 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,538 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[60] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,538 INFO cluster.YarnScheduler: Adding task set 13.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,540 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,551 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on algo-1:37329 (size: 24.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,905 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 366 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,905 INFO cluster.YarnScheduler: Removed TaskSet 13.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,906 INFO scheduler.DAGScheduler: ShuffleMapStage 13 (collect at AnalysisRunner.scala:326) finished in 0.375 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,906 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,906 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,906 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,906 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,995 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,996 INFO scheduler.DAGScheduler: Got job 11 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,996 INFO scheduler.DAGScheduler: Final stage: ResultStage 15 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,996 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,997 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:35,998 INFO scheduler.DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[63] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,000 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 66.2 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,002 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,002 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.134.245:44755 (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,003 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,003 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[63] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,003 INFO cluster.YarnScheduler: Adding task set 15.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,006 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 11) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,022 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on algo-1:37329 (size: 19.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,029 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 10.0.134.245:59834\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,038 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 11) in 32 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,038 INFO cluster.YarnScheduler: Removed TaskSet 15.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,040 INFO scheduler.DAGScheduler: ResultStage 15 (collect at AnalysisRunner.scala:326) finished in 0.041 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,041 INFO scheduler.DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,041 INFO cluster.YarnScheduler: Killing all running tasks in stage 15: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,041 INFO scheduler.DAGScheduler: Job 11 finished: collect at AnalysisRunner.scala:326, took 0.046193 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,287 INFO scheduler.DAGScheduler: Registering RDD 68 (collect at AnalysisRunner.scala:326) as input to shuffle 4\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,287 INFO scheduler.DAGScheduler: Got map stage job 12 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,287 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 16 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,287 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,288 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,288 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[68] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,294 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 87.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,298 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 28.4 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,299 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.134.245:44755 (size: 28.4 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,300 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,300 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[68] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,300 INFO cluster.YarnScheduler: Adding task set 16.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,302 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 16.0 (TID 12) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,327 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on algo-1:37329 (size: 28.4 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,730 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 16.0 (TID 12) in 428 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,731 INFO cluster.YarnScheduler: Removed TaskSet 16.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,732 INFO scheduler.DAGScheduler: ShuffleMapStage 16 (collect at AnalysisRunner.scala:326) finished in 0.441 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,732 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,734 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,734 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,734 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,783 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,784 INFO scheduler.DAGScheduler: Got job 13 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,784 INFO scheduler.DAGScheduler: Final stage: ResultStage 18 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,784 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,784 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,784 INFO scheduler.DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[71] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,791 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 172.2 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,792 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 47.4 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,793 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.134.245:44755 (size: 47.4 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,793 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,793 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[71] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,794 INFO cluster.YarnScheduler: Adding task set 18.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,795 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 13) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,808 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on algo-1:37329 (size: 47.4 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,819 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 10.0.134.245:59834\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,900 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 13) in 105 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,900 INFO cluster.YarnScheduler: Removed TaskSet 18.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,903 INFO scheduler.DAGScheduler: ResultStage 18 (collect at AnalysisRunner.scala:326) finished in 0.118 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,904 INFO scheduler.DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,906 INFO cluster.YarnScheduler: Killing all running tasks in stage 18: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:36,906 INFO scheduler.DAGScheduler: Job 13 finished: collect at AnalysisRunner.scala:326, took 0.122946 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:37,034 INFO codegen.CodeGenerator: Code generated in 14.257484 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:37,064 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:37,065 INFO scheduler.DAGScheduler: Got job 14 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:37,065 INFO scheduler.DAGScheduler: Final stage: ResultStage 19 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:37,065 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:37,066 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:37,066 INFO scheduler.DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[81] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:37,074 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 41.7 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:37,076 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:37,076 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.134.245:44755 (size: 17.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:37,077 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:37,078 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[81] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:37,078 INFO cluster.YarnScheduler: Adding task set 19.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:37,079 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 14) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4963 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:37,098 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on algo-1:37329 (size: 17.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,597 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 14) in 1518 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,598 INFO cluster.YarnScheduler: Removed TaskSet 19.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,599 INFO scheduler.DAGScheduler: ResultStage 19 (treeReduce at KLLRunner.scala:107) finished in 1.531 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,599 INFO scheduler.DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,599 INFO cluster.YarnScheduler: Killing all running tasks in stage 19: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,600 INFO scheduler.DAGScheduler: Job 14 finished: treeReduce at KLLRunner.scala:107, took 1.535173 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,801 INFO codegen.CodeGenerator: Code generated in 46.844156 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,835 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 10.0.134.245:44755 in memory (size: 28.4 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,835 INFO scheduler.DAGScheduler: Registering RDD 86 (collect at AnalysisRunner.scala:326) as input to shuffle 5\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,836 INFO scheduler.DAGScheduler: Got map stage job 15 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,836 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,836 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,836 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on algo-1:37329 in memory (size: 28.4 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,837 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,838 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,845 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 77.3 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,851 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,851 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.134.245:44755 (size: 24.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,852 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,853 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[86] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,853 INFO cluster.YarnScheduler: Adding task set 20.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,855 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 20.0 (TID 15) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,873 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 10.0.134.245:44755 in memory (size: 24.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,881 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on algo-1:37329 (size: 24.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,883 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on algo-1:37329 in memory (size: 24.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,930 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.134.245:44755 in memory (size: 47.4 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,946 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on algo-1:37329 in memory (size: 47.4 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,955 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on algo-1:37329 in memory (size: 17.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:38,957 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on 10.0.134.245:44755 in memory (size: 17.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,044 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 10.0.134.245:44755 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,048 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on algo-1:37329 in memory (size: 19.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,300 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 20.0 (TID 15) in 446 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,300 INFO cluster.YarnScheduler: Removed TaskSet 20.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,301 INFO scheduler.DAGScheduler: ShuffleMapStage 20 (collect at AnalysisRunner.scala:326) finished in 0.462 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,301 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,301 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,301 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,301 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,356 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,357 INFO scheduler.DAGScheduler: Got job 16 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,358 INFO scheduler.DAGScheduler: Final stage: ResultStage 22 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,358 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,358 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,358 INFO scheduler.DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,361 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 66.2 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,362 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,363 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.134.245:44755 (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,363 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,364 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[89] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,364 INFO cluster.YarnScheduler: Adding task set 22.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,365 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 22.0 (TID 16) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,373 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on algo-1:37329 (size: 19.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,377 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 10.0.134.245:59834\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,382 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 22.0 (TID 16) in 17 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,382 INFO cluster.YarnScheduler: Removed TaskSet 22.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,382 INFO scheduler.DAGScheduler: ResultStage 22 (collect at AnalysisRunner.scala:326) finished in 0.023 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,383 INFO scheduler.DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,383 INFO cluster.YarnScheduler: Killing all running tasks in stage 22: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,383 INFO scheduler.DAGScheduler: Job 16 finished: collect at AnalysisRunner.scala:326, took 0.027044 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,573 INFO scheduler.DAGScheduler: Registering RDD 94 (collect at AnalysisRunner.scala:326) as input to shuffle 6\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,573 INFO scheduler.DAGScheduler: Got map stage job 17 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,573 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 23 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,574 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,574 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,575 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[94] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,579 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 87.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,581 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,581 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.134.245:44755 (size: 28.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,582 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,582 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[94] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,582 INFO cluster.YarnScheduler: Adding task set 23.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,583 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 23.0 (TID 17) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:39,596 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on algo-1:37329 (size: 28.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,019 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 23.0 (TID 17) in 436 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,019 INFO cluster.YarnScheduler: Removed TaskSet 23.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,020 INFO scheduler.DAGScheduler: ShuffleMapStage 23 (collect at AnalysisRunner.scala:326) finished in 0.445 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,020 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,020 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,020 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,020 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,051 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,052 INFO scheduler.DAGScheduler: Got job 18 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,052 INFO scheduler.DAGScheduler: Final stage: ResultStage 25 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,052 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,053 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,053 INFO scheduler.DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[97] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,060 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 172.1 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,062 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 47.3 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,063 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.134.245:44755 (size: 47.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,063 INFO spark.SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,063 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[97] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,063 INFO cluster.YarnScheduler: Adding task set 25.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,065 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 25.0 (TID 18) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,078 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on algo-1:37329 (size: 47.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,089 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to 10.0.134.245:59834\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,181 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 25.0 (TID 18) in 116 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,181 INFO cluster.YarnScheduler: Removed TaskSet 25.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,182 INFO scheduler.DAGScheduler: ResultStage 25 (collect at AnalysisRunner.scala:326) finished in 0.128 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,182 INFO scheduler.DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,182 INFO cluster.YarnScheduler: Killing all running tasks in stage 25: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,182 INFO scheduler.DAGScheduler: Job 18 finished: collect at AnalysisRunner.scala:326, took 0.130770 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,279 INFO codegen.CodeGenerator: Code generated in 14.147715 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,310 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,311 INFO scheduler.DAGScheduler: Got job 19 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,311 INFO scheduler.DAGScheduler: Final stage: ResultStage 26 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,311 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,312 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,312 INFO scheduler.DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[107] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,320 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 41.7 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,321 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 17.3 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,322 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.134.245:44755 (size: 17.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,322 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,325 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[107] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,325 INFO cluster.YarnScheduler: Adding task set 26.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,326 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 26.0 (TID 19) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4963 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:40,338 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on algo-1:37329 (size: 17.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,544 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 26.0 (TID 19) in 1218 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,545 INFO scheduler.DAGScheduler: ResultStage 26 (treeReduce at KLLRunner.scala:107) finished in 1.232 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,545 INFO scheduler.DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,546 INFO cluster.YarnScheduler: Removed TaskSet 26.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,546 INFO cluster.YarnScheduler: Killing all running tasks in stage 26: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,546 INFO scheduler.DAGScheduler: Job 19 finished: treeReduce at KLLRunner.scala:107, took 1.235692 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,733 INFO codegen.CodeGenerator: Code generated in 44.585844 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,739 INFO scheduler.DAGScheduler: Registering RDD 112 (collect at AnalysisRunner.scala:326) as input to shuffle 7\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,739 INFO scheduler.DAGScheduler: Got map stage job 20 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,739 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 27 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,739 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,740 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,740 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[112] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,745 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 77.3 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,747 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,750 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.0.134.245:44755 (size: 24.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,750 INFO spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,751 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[112] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,751 INFO cluster.YarnScheduler: Adding task set 27.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,752 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 20) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:41,766 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on algo-1:37329 (size: 24.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,066 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 20) in 314 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,067 INFO cluster.YarnScheduler: Removed TaskSet 27.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,067 INFO scheduler.DAGScheduler: ShuffleMapStage 27 (collect at AnalysisRunner.scala:326) finished in 0.325 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,067 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,067 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,067 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,067 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,106 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,107 INFO scheduler.DAGScheduler: Got job 21 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,107 INFO scheduler.DAGScheduler: Final stage: ResultStage 29 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,107 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,107 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,108 INFO scheduler.DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[115] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,110 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 66.2 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,111 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,112 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.0.134.245:44755 (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,112 INFO spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,113 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[115] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,113 INFO cluster.YarnScheduler: Adding task set 29.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,114 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 29.0 (TID 21) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,126 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on algo-1:37329 (size: 19.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,131 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to 10.0.134.245:59834\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,135 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 29.0 (TID 21) in 21 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,135 INFO cluster.YarnScheduler: Removed TaskSet 29.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,136 INFO scheduler.DAGScheduler: ResultStage 29 (collect at AnalysisRunner.scala:326) finished in 0.028 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,136 INFO scheduler.DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,136 INFO cluster.YarnScheduler: Killing all running tasks in stage 29: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,137 INFO scheduler.DAGScheduler: Job 21 finished: collect at AnalysisRunner.scala:326, took 0.030274 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,208 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,213 INFO scheduler.DAGScheduler: Registering RDD 123 (countByKey at ColumnProfiler.scala:592) as input to shuffle 8\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,213 INFO scheduler.DAGScheduler: Got job 22 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,213 INFO scheduler.DAGScheduler: Final stage: ResultStage 31 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,213 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,213 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 30)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,214 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[123] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,220 INFO memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 34.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,221 INFO memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,222 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.0.134.245:44755 (size: 15.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,222 INFO spark.SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,223 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[123] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,223 INFO cluster.YarnScheduler: Adding task set 30.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,224 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 30.0 (TID 22) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:42,232 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on algo-1:37329 (size: 15.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,792 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 30.0 (TID 22) in 1567 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,792 INFO cluster.YarnScheduler: Removed TaskSet 30.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,795 INFO scheduler.DAGScheduler: ShuffleMapStage 30 (countByKey at ColumnProfiler.scala:592) finished in 1.580 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,795 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,795 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,795 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 31)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,795 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,795 INFO scheduler.DAGScheduler: Submitting ResultStage 31 (ShuffledRDD[124] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,797 INFO memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 5.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,822 INFO memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,822 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.0.134.245:44755 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,823 INFO spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,823 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (ShuffledRDD[124] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,823 INFO cluster.YarnScheduler: Adding task set 31.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,825 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 31.0 (TID 23) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,833 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on algo-1:37329 in memory (size: 24.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,840 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on 10.0.134.245:44755 in memory (size: 24.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,843 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on algo-1:37329 (size: 3.0 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,849 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on algo-1:37329 in memory (size: 19.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,852 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to 10.0.134.245:59834\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,855 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on 10.0.134.245:44755 in memory (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,858 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on 10.0.134.245:44755 in memory (size: 17.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,867 INFO storage.BlockManagerInfo: Removed broadcast_21_piece0 on algo-1:37329 in memory (size: 17.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,883 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 31.0 (TID 23) in 59 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,883 INFO cluster.YarnScheduler: Removed TaskSet 31.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,884 INFO scheduler.DAGScheduler: ResultStage 31 (countByKey at ColumnProfiler.scala:592) finished in 0.088 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,884 INFO scheduler.DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,885 INFO cluster.YarnScheduler: Killing all running tasks in stage 31: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,885 INFO scheduler.DAGScheduler: Job 22 finished: countByKey at ColumnProfiler.scala:592, took 1.677343 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,901 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on 10.0.134.245:44755 in memory (size: 47.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,905 INFO storage.BlockManagerInfo: Removed broadcast_20_piece0 on algo-1:37329 in memory (size: 47.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,913 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on 10.0.134.245:44755 in memory (size: 24.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,919 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on algo-1:37329 in memory (size: 24.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,924 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on algo-1:37329 in memory (size: 28.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,926 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on 10.0.134.245:44755 in memory (size: 28.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,934 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on 10.0.134.245:44755 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:43,940 INFO storage.BlockManagerInfo: Removed broadcast_23_piece0 on algo-1:37329 in memory (size: 19.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,044 INFO scheduler.DAGScheduler: Registering RDD 129 (collect at AnalysisRunner.scala:326) as input to shuffle 9\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,044 INFO scheduler.DAGScheduler: Got map stage job 23 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,044 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 32 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,044 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,045 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,045 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[129] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,049 INFO memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 87.1 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,051 INFO memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,051 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.0.134.245:44755 (size: 28.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,052 INFO spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,052 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[129] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,052 INFO cluster.YarnScheduler: Adding task set 32.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,054 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 32.0 (TID 24) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,064 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on algo-1:37329 (size: 28.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,514 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 32.0 (TID 24) in 461 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,514 INFO cluster.YarnScheduler: Removed TaskSet 32.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,514 INFO scheduler.DAGScheduler: ShuffleMapStage 32 (collect at AnalysisRunner.scala:326) finished in 0.468 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,515 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,515 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,515 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,515 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,551 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,552 INFO scheduler.DAGScheduler: Got job 24 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,552 INFO scheduler.DAGScheduler: Final stage: ResultStage 34 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,552 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,552 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,553 INFO scheduler.DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[132] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,558 INFO memory.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 171.9 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,560 INFO memory.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 47.2 KiB, free 1457.8 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,560 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.0.134.245:44755 (size: 47.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,565 INFO spark.SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,565 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[132] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,565 INFO cluster.YarnScheduler: Adding task set 34.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,567 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 34.0 (TID 25) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,585 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on algo-1:37329 (size: 47.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,596 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to 10.0.134.245:59834\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,688 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 34.0 (TID 25) in 121 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,688 INFO cluster.YarnScheduler: Removed TaskSet 34.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,689 INFO scheduler.DAGScheduler: ResultStage 34 (collect at AnalysisRunner.scala:326) finished in 0.136 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,689 INFO scheduler.DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,690 INFO cluster.YarnScheduler: Killing all running tasks in stage 34: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,690 INFO scheduler.DAGScheduler: Job 24 finished: collect at AnalysisRunner.scala:326, took 0.138289 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,849 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,851 INFO scheduler.DAGScheduler: Got job 25 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,851 INFO scheduler.DAGScheduler: Final stage: ResultStage 35 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,851 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,851 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,852 INFO scheduler.DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[142] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,858 INFO memory.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 41.7 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,860 INFO memory.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 17.2 KiB, free 1457.7 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,861 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.0.134.245:44755 (size: 17.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,861 INFO spark.SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,862 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[142] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,862 INFO cluster.YarnScheduler: Adding task set 35.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,864 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 35.0 (TID 26) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4963 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:44,875 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on algo-1:37329 (size: 17.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,096 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 35.0 (TID 26) in 1233 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,097 INFO scheduler.DAGScheduler: ResultStage 35 (treeReduce at KLLRunner.scala:107) finished in 1.245 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,098 INFO scheduler.DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,098 INFO cluster.YarnScheduler: Removed TaskSet 35.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,098 INFO cluster.YarnScheduler: Killing all running tasks in stage 35: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,099 INFO scheduler.DAGScheduler: Job 25 finished: treeReduce at KLLRunner.scala:107, took 1.248668 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,244 INFO scheduler.DAGScheduler: Registering RDD 147 (collect at AnalysisRunner.scala:326) as input to shuffle 10\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,244 INFO scheduler.DAGScheduler: Got map stage job 26 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,244 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 36 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,244 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,245 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,245 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[147] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,248 INFO memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 77.3 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,250 INFO memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 24.3 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,250 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.0.134.245:44755 (size: 24.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,250 INFO spark.SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,251 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[147] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,251 INFO cluster.YarnScheduler: Adding task set 36.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,252 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 36.0 (TID 27) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,263 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on algo-1:37329 (size: 24.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,406 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 36.0 (TID 27) in 154 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,406 INFO cluster.YarnScheduler: Removed TaskSet 36.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,410 INFO scheduler.DAGScheduler: ShuffleMapStage 36 (collect at AnalysisRunner.scala:326) finished in 0.165 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,412 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,412 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,412 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,412 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,455 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,456 INFO scheduler.DAGScheduler: Got job 27 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,456 INFO scheduler.DAGScheduler: Final stage: ResultStage 38 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,456 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 37)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,456 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,456 INFO scheduler.DAGScheduler: Submitting ResultStage 38 (MapPartitionsRDD[150] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,458 INFO memory.MemoryStore: Block broadcast_30 stored as values in memory (estimated size 66.2 KiB, free 1457.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,460 INFO memory.MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,461 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.0.134.245:44755 (size: 19.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,461 INFO spark.SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,461 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 38 (MapPartitionsRDD[150] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,461 INFO cluster.YarnScheduler: Adding task set 38.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,462 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 38.0 (TID 28) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,472 INFO storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on algo-1:37329 (size: 19.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,475 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to 10.0.134.245:59834\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,482 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 38.0 (TID 28) in 20 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,483 INFO cluster.YarnScheduler: Removed TaskSet 38.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,483 INFO scheduler.DAGScheduler: ResultStage 38 (collect at AnalysisRunner.scala:326) finished in 0.026 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,484 INFO scheduler.DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,484 INFO cluster.YarnScheduler: Killing all running tasks in stage 38: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,484 INFO scheduler.DAGScheduler: Job 27 finished: collect at AnalysisRunner.scala:326, took 0.028859 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,545 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,546 INFO scheduler.DAGScheduler: Registering RDD 158 (countByKey at ColumnProfiler.scala:592) as input to shuffle 11\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,546 INFO scheduler.DAGScheduler: Got job 28 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,547 INFO scheduler.DAGScheduler: Final stage: ResultStage 40 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,547 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 39)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,547 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 39)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,548 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[158] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,556 INFO memory.MemoryStore: Block broadcast_31 stored as values in memory (estimated size 34.1 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,558 INFO memory.MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,558 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.0.134.245:44755 (size: 15.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,559 INFO spark.SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,559 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[158] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,559 INFO cluster.YarnScheduler: Adding task set 39.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,560 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 39.0 (TID 29) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,569 INFO storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on algo-1:37329 (size: 15.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,693 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 39.0 (TID 29) in 133 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,693 INFO cluster.YarnScheduler: Removed TaskSet 39.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,693 INFO scheduler.DAGScheduler: ShuffleMapStage 39 (countByKey at ColumnProfiler.scala:592) finished in 0.143 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,693 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,693 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,693 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 40)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,693 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,694 INFO scheduler.DAGScheduler: Submitting ResultStage 40 (ShuffledRDD[159] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,695 INFO memory.MemoryStore: Block broadcast_32 stored as values in memory (estimated size 5.1 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,697 INFO memory.MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,697 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.0.134.245:44755 (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,698 INFO spark.SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,698 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (ShuffledRDD[159] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,698 INFO cluster.YarnScheduler: Adding task set 40.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,700 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 40.0 (TID 30) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,710 INFO storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on algo-1:37329 (size: 3.0 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,713 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to 10.0.134.245:59834\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,726 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 40.0 (TID 30) in 26 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,727 INFO cluster.YarnScheduler: Removed TaskSet 40.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,727 INFO scheduler.DAGScheduler: ResultStage 40 (countByKey at ColumnProfiler.scala:592) finished in 0.033 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,728 INFO scheduler.DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,728 INFO cluster.YarnScheduler: Killing all running tasks in stage 40: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,729 INFO scheduler.DAGScheduler: Job 28 finished: countByKey at ColumnProfiler.scala:592, took 0.183379 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,812 INFO scheduler.DAGScheduler: Registering RDD 164 (collect at AnalysisRunner.scala:326) as input to shuffle 12\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,813 INFO scheduler.DAGScheduler: Got map stage job 29 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,813 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 41 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,813 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,814 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,814 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[164] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,817 INFO memory.MemoryStore: Block broadcast_33 stored as values in memory (estimated size 87.1 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,819 INFO memory.MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 28.3 KiB, free 1457.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,820 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.0.134.245:44755 (size: 28.3 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,820 INFO spark.SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,820 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[164] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,820 INFO cluster.YarnScheduler: Adding task set 41.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,821 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 41.0 (TID 31) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:46,831 INFO storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on algo-1:37329 (size: 28.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,229 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 41.0 (TID 31) in 408 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,230 INFO scheduler.DAGScheduler: ShuffleMapStage 41 (collect at AnalysisRunner.scala:326) finished in 0.416 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,230 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,230 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,230 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,230 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,232 INFO cluster.YarnScheduler: Removed TaskSet 41.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,263 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,263 INFO scheduler.DAGScheduler: Got job 30 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,263 INFO scheduler.DAGScheduler: Final stage: ResultStage 43 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,263 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,264 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,264 INFO scheduler.DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[167] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,269 INFO memory.MemoryStore: Block broadcast_34 stored as values in memory (estimated size 172.0 KiB, free 1457.2 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,273 INFO memory.MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 47.2 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,274 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.0.134.245:44755 (size: 47.2 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,275 INFO spark.SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,275 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[167] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,275 INFO cluster.YarnScheduler: Adding task set 43.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,277 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 43.0 (TID 32) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,288 INFO storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on algo-1:37329 (size: 47.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,298 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to 10.0.134.245:59834\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,358 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 43.0 (TID 32) in 81 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,358 INFO cluster.YarnScheduler: Removed TaskSet 43.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,358 INFO scheduler.DAGScheduler: ResultStage 43 (collect at AnalysisRunner.scala:326) finished in 0.093 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,359 INFO scheduler.DAGScheduler: Job 30 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,359 INFO cluster.YarnScheduler: Killing all running tasks in stage 43: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,360 INFO scheduler.DAGScheduler: Job 30 finished: collect at AnalysisRunner.scala:326, took 0.096952 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,439 INFO codegen.CodeGenerator: Code generated in 15.541348 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,491 INFO spark.SparkContext: Starting job: treeReduce at KLLRunner.scala:107\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,493 INFO scheduler.DAGScheduler: Got job 31 (treeReduce at KLLRunner.scala:107) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,494 INFO scheduler.DAGScheduler: Final stage: ResultStage 44 (treeReduce at KLLRunner.scala:107)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,494 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,495 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,499 INFO scheduler.DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[177] at treeReduce at KLLRunner.scala:107), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,506 INFO memory.MemoryStore: Block broadcast_35 stored as values in memory (estimated size 41.1 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,508 INFO memory.MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 1457.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,509 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.0.134.245:44755 (size: 17.1 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,509 INFO spark.SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,510 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[177] at treeReduce at KLLRunner.scala:107) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,510 INFO cluster.YarnScheduler: Adding task set 44.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,512 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 44.0 (TID 33) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4963 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:47,521 INFO storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on algo-1:37329 (size: 17.1 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,741 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 44.0 (TID 33) in 1229 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,741 INFO cluster.YarnScheduler: Removed TaskSet 44.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,741 INFO scheduler.DAGScheduler: ResultStage 44 (treeReduce at KLLRunner.scala:107) finished in 1.240 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,742 INFO scheduler.DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,742 INFO cluster.YarnScheduler: Killing all running tasks in stage 44: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,742 INFO scheduler.DAGScheduler: Job 31 finished: treeReduce at KLLRunner.scala:107, took 1.249683 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,837 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on algo-1:37329 in memory (size: 28.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,840 INFO storage.BlockManagerInfo: Removed broadcast_33_piece0 on 10.0.134.245:44755 in memory (size: 28.3 KiB, free: 1458.3 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,856 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on 10.0.134.245:44755 in memory (size: 47.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,864 INFO storage.BlockManagerInfo: Removed broadcast_27_piece0 on algo-1:37329 in memory (size: 47.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,867 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on 10.0.134.245:44755 in memory (size: 3.0 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,867 INFO storage.BlockManagerInfo: Removed broadcast_32_piece0 on algo-1:37329 in memory (size: 3.0 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,871 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on 10.0.134.245:44755 in memory (size: 15.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,872 INFO storage.BlockManagerInfo: Removed broadcast_31_piece0 on algo-1:37329 in memory (size: 15.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,874 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on 10.0.134.245:44755 in memory (size: 15.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,880 INFO storage.BlockManagerInfo: Removed broadcast_24_piece0 on algo-1:37329 in memory (size: 15.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,883 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on 10.0.134.245:44755 in memory (size: 17.2 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,884 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on algo-1:37329 in memory (size: 17.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,889 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on 10.0.134.245:44755 in memory (size: 17.1 KiB, free: 1458.4 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,891 INFO storage.BlockManagerInfo: Removed broadcast_35_piece0 on algo-1:37329 in memory (size: 17.1 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,899 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on 10.0.134.245:44755 in memory (size: 19.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,910 INFO storage.BlockManagerInfo: Removed broadcast_30_piece0 on algo-1:37329 in memory (size: 19.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,914 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on 10.0.134.245:44755 in memory (size: 24.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,915 INFO storage.BlockManagerInfo: Removed broadcast_29_piece0 on algo-1:37329 in memory (size: 24.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,921 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on 10.0.134.245:44755 in memory (size: 47.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,921 INFO storage.BlockManagerInfo: Removed broadcast_34_piece0 on algo-1:37329 in memory (size: 47.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,923 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on 10.0.134.245:44755 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,924 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on algo-1:37329 in memory (size: 3.0 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,928 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on 10.0.134.245:44755 in memory (size: 28.3 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:48,929 INFO storage.BlockManagerInfo: Removed broadcast_26_piece0 on algo-1:37329 in memory (size: 28.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,052 INFO codegen.CodeGenerator: Code generated in 62.721608 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,065 INFO scheduler.DAGScheduler: Registering RDD 182 (collect at AnalysisRunner.scala:326) as input to shuffle 13\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,065 INFO scheduler.DAGScheduler: Got map stage job 32 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,066 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 45 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,066 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,066 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,067 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[182] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,070 INFO memory.MemoryStore: Block broadcast_36 stored as values in memory (estimated size 79.5 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,072 INFO memory.MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 25.3 KiB, free 1458.1 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,072 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.0.134.245:44755 (size: 25.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,073 INFO spark.SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,073 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[182] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,074 INFO cluster.YarnScheduler: Adding task set 45.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,075 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 45.0 (TID 34) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,085 INFO storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on algo-1:37329 (size: 25.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,308 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 45.0 (TID 34) in 233 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,308 INFO cluster.YarnScheduler: Removed TaskSet 45.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,309 INFO scheduler.DAGScheduler: ShuffleMapStage 45 (collect at AnalysisRunner.scala:326) finished in 0.241 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,309 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,309 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,310 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,310 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,413 INFO codegen.CodeGenerator: Code generated in 59.664437 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,432 INFO spark.SparkContext: Starting job: collect at AnalysisRunner.scala:326\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,434 INFO scheduler.DAGScheduler: Got job 33 (collect at AnalysisRunner.scala:326) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,435 INFO scheduler.DAGScheduler: Final stage: ResultStage 47 (collect at AnalysisRunner.scala:326)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,435 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,435 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,436 INFO scheduler.DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[185] at collect at AnalysisRunner.scala:326), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,438 INFO memory.MemoryStore: Block broadcast_37 stored as values in memory (estimated size 67.7 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,440 INFO memory.MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 19.9 KiB, free 1458.0 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,441 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.0.134.245:44755 (size: 19.9 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,441 INFO spark.SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,442 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[185] at collect at AnalysisRunner.scala:326) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,442 INFO cluster.YarnScheduler: Adding task set 47.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,443 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 47.0 (TID 35) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,457 INFO storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on algo-1:37329 (size: 19.9 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,469 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to 10.0.134.245:59834\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,521 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 47.0 (TID 35) in 78 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,521 INFO cluster.YarnScheduler: Removed TaskSet 47.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,522 INFO scheduler.DAGScheduler: ResultStage 47 (collect at AnalysisRunner.scala:326) finished in 0.085 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,523 INFO scheduler.DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,523 INFO cluster.YarnScheduler: Killing all running tasks in stage 47: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,523 INFO scheduler.DAGScheduler: Job 33 finished: collect at AnalysisRunner.scala:326, took 0.090419 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,575 INFO spark.SparkContext: Starting job: countByKey at ColumnProfiler.scala:592\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,577 INFO scheduler.DAGScheduler: Registering RDD 193 (countByKey at ColumnProfiler.scala:592) as input to shuffle 14\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,577 INFO scheduler.DAGScheduler: Got job 34 (countByKey at ColumnProfiler.scala:592) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,577 INFO scheduler.DAGScheduler: Final stage: ResultStage 49 (countByKey at ColumnProfiler.scala:592)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,577 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,577 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 48)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,578 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[193] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,589 INFO memory.MemoryStore: Block broadcast_38 stored as values in memory (estimated size 34.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,591 INFO memory.MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 15.2 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,591 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.0.134.245:44755 (size: 15.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,592 INFO spark.SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,593 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[193] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,593 INFO cluster.YarnScheduler: Adding task set 48.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,594 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 48.0 (TID 36) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,604 INFO storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on algo-1:37329 (size: 15.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,722 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 48.0 (TID 36) in 128 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,722 INFO cluster.YarnScheduler: Removed TaskSet 48.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,723 INFO scheduler.DAGScheduler: ShuffleMapStage 48 (countByKey at ColumnProfiler.scala:592) finished in 0.145 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,723 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,723 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,723 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 49)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,723 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,724 INFO scheduler.DAGScheduler: Submitting ResultStage 49 (ShuffledRDD[194] at countByKey at ColumnProfiler.scala:592), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,727 INFO memory.MemoryStore: Block broadcast_39 stored as values in memory (estimated size 5.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,729 INFO memory.MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 3.0 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,735 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.0.134.245:44755 (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,735 INFO spark.SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,735 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (ShuffledRDD[194] at countByKey at ColumnProfiler.scala:592) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,735 INFO cluster.YarnScheduler: Adding task set 49.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,737 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 49.0 (TID 37) (algo-1, executor 1, partition 0, NODE_LOCAL, 4282 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,745 INFO storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on algo-1:37329 (size: 3.0 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,748 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to 10.0.134.245:59834\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,758 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 49.0 (TID 37) in 22 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,758 INFO cluster.YarnScheduler: Removed TaskSet 49.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,758 INFO scheduler.DAGScheduler: ResultStage 49 (countByKey at ColumnProfiler.scala:592) finished in 0.032 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,759 INFO scheduler.DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,759 INFO cluster.YarnScheduler: Killing all running tasks in stage 49: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,759 INFO scheduler.DAGScheduler: Job 34 finished: countByKey at ColumnProfiler.scala:592, took 0.183979 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:49,989 INFO FileUtil: Write to file constraints.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,016 INFO codegen.CodeGenerator: Code generated in 7.630658 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,021 INFO scheduler.DAGScheduler: Registering RDD 199 (count at StatsGenerator.scala:66) as input to shuffle 15\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,021 INFO scheduler.DAGScheduler: Got map stage job 35 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,021 INFO scheduler.DAGScheduler: Final stage: ShuffleMapStage 50 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,021 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,022 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,022 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[199] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,025 INFO memory.MemoryStore: Block broadcast_40 stored as values in memory (estimated size 26.2 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,029 INFO memory.MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 11.4 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,030 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.0.134.245:44755 (size: 11.4 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,030 INFO spark.SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,030 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[199] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,030 INFO cluster.YarnScheduler: Adding task set 50.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,031 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 50.0 (TID 38) (algo-1, executor 1, partition 0, PROCESS_LOCAL, 4952 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,040 INFO storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on algo-1:37329 (size: 11.4 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,072 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 50.0 (TID 38) in 41 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,072 INFO cluster.YarnScheduler: Removed TaskSet 50.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,072 INFO scheduler.DAGScheduler: ShuffleMapStage 50 (count at StatsGenerator.scala:66) finished in 0.050 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,072 INFO scheduler.DAGScheduler: looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,073 INFO scheduler.DAGScheduler: running: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,073 INFO scheduler.DAGScheduler: waiting: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,073 INFO scheduler.DAGScheduler: failed: Set()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,094 INFO codegen.CodeGenerator: Code generated in 8.288643 ms\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,103 INFO spark.SparkContext: Starting job: count at StatsGenerator.scala:66\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,104 INFO scheduler.DAGScheduler: Got job 36 (count at StatsGenerator.scala:66) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,104 INFO scheduler.DAGScheduler: Final stage: ResultStage 52 (count at StatsGenerator.scala:66)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,104 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 51)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,104 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,104 INFO scheduler.DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[202] at count at StatsGenerator.scala:66), which has no missing parents\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,106 INFO memory.MemoryStore: Block broadcast_41 stored as values in memory (estimated size 11.1 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,107 INFO memory.MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 1457.9 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,107 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.0.134.245:44755 (size: 5.5 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,108 INFO spark.SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1513\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,110 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[202] at count at StatsGenerator.scala:66) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,110 INFO cluster.YarnScheduler: Adding task set 52.0 with 1 tasks resource profile 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,111 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 52.0 (TID 39) (algo-1, executor 1, partition 0, NODE_LOCAL, 4464 bytes) taskResourceAssignments Map()\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,119 INFO storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on algo-1:37329 (size: 5.5 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,122 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to 10.0.134.245:59834\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,138 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 52.0 (TID 39) in 27 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,138 INFO cluster.YarnScheduler: Removed TaskSet 52.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,139 INFO scheduler.DAGScheduler: ResultStage 52 (count at StatsGenerator.scala:66) finished in 0.034 s\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,140 INFO scheduler.DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,140 INFO cluster.YarnScheduler: Killing all running tasks in stage 52: Stage finished\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,142 INFO scheduler.DAGScheduler: Job 36 finished: count at StatsGenerator.scala:66, took 0.038741 s\u001b[0m\n",
      "\n",
      "\u001b[34m2023-05-10 08:26:50,917 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on algo-1:37329 in memory (size: 5.5 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,931 INFO storage.BlockManagerInfo: Removed broadcast_41_piece0 on 10.0.134.245:44755 in memory (size: 5.5 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,937 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on 10.0.134.245:44755 in memory (size: 3.0 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,941 INFO storage.BlockManagerInfo: Removed broadcast_39_piece0 on algo-1:37329 in memory (size: 3.0 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,947 INFO storage.BlockManagerInfo: Removed broadcast_38_piece0 on 10.0.134.245:44755 in memory (size: 15.2 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,947 INFO storage.BlockManagerInfo: Removed broadcast_38_piece0 on algo-1:37329 in memory (size: 15.2 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,954 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on 10.0.134.245:44755 in memory (size: 11.4 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,956 INFO storage.BlockManagerInfo: Removed broadcast_40_piece0 on algo-1:37329 in memory (size: 11.4 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,963 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on 10.0.134.245:44755 in memory (size: 25.3 KiB, free: 1458.5 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,964 INFO storage.BlockManagerInfo: Removed broadcast_36_piece0 on algo-1:37329 in memory (size: 25.3 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,967 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on 10.0.134.245:44755 in memory (size: 19.9 KiB, free: 1458.6 MiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,967 INFO storage.BlockManagerInfo: Removed broadcast_37_piece0 on algo-1:37329 in memory (size: 19.9 KiB, free: 5.7 GiB)\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:50,983 INFO FileUtil: Write to file statistics.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,006 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,055 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,056 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,067 INFO cluster.YarnClientSchedulerBackend: YARN client scheduler backend Stopped\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,094 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,133 INFO memory.MemoryStore: MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,136 INFO storage.BlockManager: BlockManager stopped\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,150 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,163 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,191 INFO spark.SparkContext: Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,191 INFO Main: Completed: Job completed successfully with no violations.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,191 INFO Main: Write to file /opt/ml/output/message.\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,203 INFO util.ShutdownHookManager: Shutdown hook called\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,204 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-4efb6f56-18fd-434a-90c2-d2a02cf39e17\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,217 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-36275649-b250-4c5c-b479-b6bc362172c1\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,305 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\u001b[0m\n",
      "\u001b[34m2023-05-10 08:26:51,305 - DefaultDataAnalyzer - INFO - Spark job completed.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.processing.ProcessingJob at 0x7f6165993110>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "baseline_data = \"datasets/train-test/test_data_with_headers.csv\"\n",
    "baseline_results_uri = f\"s3://{bucket}/{prefix}/data/baselining/test-header-data-results\"\n",
    "baseline_job_name = f\"PdM-Baseline-Job-Data-Monitor-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
    "\n",
    "test_data_drift_monitor.suggest_baseline(\n",
    "    job_name = baseline_job_name,\n",
    "    baseline_dataset = baseline_data,\n",
    "    dataset_format = DatasetFormat.csv(header = True),\n",
    "    output_s3_uri = baseline_results_uri,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_job = test_data_drift_monitor.latest_baselining_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0           voltmean_3h\n",
       "1         rotatemean_3h\n",
       "2       pressuremean_3h\n",
       "3      vibrationmean_3h\n",
       "4             voltsd_3h\n",
       "5           rotatesd_3h\n",
       "6         pressuresd_3h\n",
       "7        vibrationsd_3h\n",
       "8          voltmean_24h\n",
       "9        rotatemean_24h\n",
       "10     pressuremean_24h\n",
       "11    vibrationmean_24h\n",
       "12           voltsd_24h\n",
       "13         rotatesd_24h\n",
       "14       pressuresd_24h\n",
       "15      vibrationsd_24h\n",
       "16          error1count\n",
       "17          error2count\n",
       "18          error3count\n",
       "19          error4count\n",
       "20          error5count\n",
       "21                comp1\n",
       "22                comp2\n",
       "23                comp3\n",
       "24                comp4\n",
       "25                  age\n",
       "26         model_model1\n",
       "27         model_model2\n",
       "28         model_model3\n",
       "29         model_model4\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_df = pd.io.json.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Monitoring Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_path = f\"s3://{bucket}/{prefix}/code/datacapture_preprocessing.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_schedule_name = \"PdM-DataDrift-Monitoring-Schedule-Header-Data\"\n",
    "endpoint_name = \"PdM-SKLearn-Pipeline-Endpoint-ReTraining\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.model_monitor.model_monitoring:Creating Monitoring Schedule with name: PdM-DataDrift-Monitoring-Schedule-Header-Data\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "test_data_drift_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name = monitor_schedule_name,\n",
    "    statistics = test_data_drift_monitor.baseline_statistics(),\n",
    "    record_preprocessor_script = preprocessor_path,\n",
    "    endpoint_input = endpoint_name,\n",
    "    constraints = test_data_drift_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression = CronExpressionGenerator.hourly(),\n",
    "    output_s3_uri = baseline_results_uri,\n",
    "    enable_cloudwatch_metrics = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_drift_monitor.monitoring_schedule_name = \"PdM-DataDrift-Monitoring-Schedule-Header-Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer, JSONSerializer\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name = endpoint_name, \n",
    "    sagemaker_session = sagemaker_session,\n",
    "    serializer = JSONSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "for item in test_data.to_numpy()[:100]:\n",
    "    item = [item.tolist()]\n",
    "    result = predictor.predict(item)\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_drift_monitor.list_executions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_drift_monitor.list_executions()[-1].describe()[\"ProcessingJobStatus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CompletedWithViolations: Job completed successfully with 1 violations.'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_drift_monitor.list_executions()[-1].describe()[\"ExitMessage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>constraint_check_type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Missing columns</td>\n",
       "      <td>missing_column_check</td>\n",
       "      <td>There are missing columns in current dataset. Number of columns in current dataset: 3, Number of columns in baseline constraints: 30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_name constraint_check_type  \\\n",
       "0  Missing columns  missing_column_check   \n",
       "\n",
       "                                                                                                                            description  \n",
       "0  There are missing columns in current dataset. Number of columns in current dataset: 3, Number of columns in baseline constraints: 30  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violations = test_data_drift_monitor.latest_monitoring_constraint_violations()\n",
    "pd.set_option(\"display.max_colwidth\", -1)\n",
    "constraints_df = pd.io.json.json_normalize(violations.body_dict[\"violations\"])\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>voltmean_3h</th>\n",
       "      <th>rotatemean_3h</th>\n",
       "      <th>pressuremean_3h</th>\n",
       "      <th>vibrationmean_3h</th>\n",
       "      <th>voltsd_3h</th>\n",
       "      <th>rotatesd_3h</th>\n",
       "      <th>pressuresd_3h</th>\n",
       "      <th>vibrationsd_3h</th>\n",
       "      <th>voltmean_24h</th>\n",
       "      <th>rotatemean_24h</th>\n",
       "      <th>...</th>\n",
       "      <th>error5count</th>\n",
       "      <th>comp1</th>\n",
       "      <th>comp2</th>\n",
       "      <th>comp3</th>\n",
       "      <th>comp4</th>\n",
       "      <th>age</th>\n",
       "      <th>model_model1</th>\n",
       "      <th>model_model2</th>\n",
       "      <th>model_model3</th>\n",
       "      <th>model_model4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170.301017</td>\n",
       "      <td>449.036995</td>\n",
       "      <td>94.805205</td>\n",
       "      <td>40.816797</td>\n",
       "      <td>11.061667</td>\n",
       "      <td>58.425055</td>\n",
       "      <td>4.931305</td>\n",
       "      <td>2.428740</td>\n",
       "      <td>176.844376</td>\n",
       "      <td>456.598107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.875</td>\n",
       "      <td>13.875</td>\n",
       "      <td>118.875</td>\n",
       "      <td>28.875</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165.339972</td>\n",
       "      <td>435.660354</td>\n",
       "      <td>103.351320</td>\n",
       "      <td>31.892462</td>\n",
       "      <td>10.717864</td>\n",
       "      <td>26.009485</td>\n",
       "      <td>22.071933</td>\n",
       "      <td>6.020669</td>\n",
       "      <td>176.141499</td>\n",
       "      <td>453.900566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.000</td>\n",
       "      <td>14.000</td>\n",
       "      <td>119.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>183.752875</td>\n",
       "      <td>463.058640</td>\n",
       "      <td>109.525083</td>\n",
       "      <td>41.945037</td>\n",
       "      <td>9.369264</td>\n",
       "      <td>43.646584</td>\n",
       "      <td>10.859804</td>\n",
       "      <td>9.395067</td>\n",
       "      <td>175.764202</td>\n",
       "      <td>451.753148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.125</td>\n",
       "      <td>14.125</td>\n",
       "      <td>119.125</td>\n",
       "      <td>29.125</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>177.866822</td>\n",
       "      <td>506.692032</td>\n",
       "      <td>98.745260</td>\n",
       "      <td>39.861149</td>\n",
       "      <td>16.596090</td>\n",
       "      <td>38.086352</td>\n",
       "      <td>10.410456</td>\n",
       "      <td>5.418325</td>\n",
       "      <td>175.352459</td>\n",
       "      <td>455.124136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.250</td>\n",
       "      <td>14.250</td>\n",
       "      <td>119.250</td>\n",
       "      <td>29.250</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167.471524</td>\n",
       "      <td>425.963281</td>\n",
       "      <td>111.996389</td>\n",
       "      <td>39.396999</td>\n",
       "      <td>9.015089</td>\n",
       "      <td>63.342755</td>\n",
       "      <td>4.648154</td>\n",
       "      <td>6.365146</td>\n",
       "      <td>174.712824</td>\n",
       "      <td>451.436346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.375</td>\n",
       "      <td>14.375</td>\n",
       "      <td>119.375</td>\n",
       "      <td>29.375</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   voltmean_3h  rotatemean_3h  pressuremean_3h  vibrationmean_3h  voltsd_3h  \\\n",
       "0  170.301017   449.036995     94.805205        40.816797         11.061667   \n",
       "1  165.339972   435.660354     103.351320       31.892462         10.717864   \n",
       "2  183.752875   463.058640     109.525083       41.945037         9.369264    \n",
       "3  177.866822   506.692032     98.745260        39.861149         16.596090   \n",
       "4  167.471524   425.963281     111.996389       39.396999         9.015089    \n",
       "\n",
       "   rotatesd_3h  pressuresd_3h  vibrationsd_3h  voltmean_24h  rotatemean_24h  \\\n",
       "0  58.425055    4.931305       2.428740        176.844376    456.598107       \n",
       "1  26.009485    22.071933      6.020669        176.141499    453.900566       \n",
       "2  43.646584    10.859804      9.395067        175.764202    451.753148       \n",
       "3  38.086352    10.410456      5.418325        175.352459    455.124136       \n",
       "4  63.342755    4.648154       6.365146        174.712824    451.436346       \n",
       "\n",
       "   ...  error5count   comp1   comp2    comp3   comp4  age  model_model1  \\\n",
       "0  ...  0.0          28.875  13.875  118.875  28.875  18   0              \n",
       "1  ...  0.0          29.000  14.000  119.000  29.000  18   0              \n",
       "2  ...  0.0          29.125  14.125  119.125  29.125  18   0              \n",
       "3  ...  0.0          29.250  14.250  119.250  29.250  18   0              \n",
       "4  ...  0.0          29.375  14.375  119.375  29.375  18   0              \n",
       "\n",
       "   model_model2  model_model3  model_model4  \n",
       "0  0             1             0             \n",
       "1  0             1             0             \n",
       "2  0             1             0             \n",
       "3  0             1             0             \n",
       "4  0             1             0             \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
